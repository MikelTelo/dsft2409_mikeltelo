{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Modelo base cargado correctamente desde 'C:\\Users\\mikel\\OneDrive\\Documentos\\TB-DS-BIO-23.09.24\\REPOSITORIOS\\Mikel\\dsft2409_mikeltelo\\PROJECTS\\kaggle_clip_counting\\modelo_final\\modelo_clip_count_p.h5'\n",
      "🔄 El modelo base es Sequential. Añadiendo entrada explícita.\n",
      "🔄 Salida con 2 dimensiones, aplicando capa Dense directamente.\n",
      "✅ Modelo ajustado para Transfer Learning listo para ser entrenado.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_52\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_52\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sequential_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,305,089</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sequential_2 (\u001b[38;5;33mSequential\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │     \u001b[38;5;34m3,305,089\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,330,178</span> (12.70 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,330,178\u001b[0m (12.70 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,089</span> (98.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,089\u001b[0m (98.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,305,089</span> (12.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,305,089\u001b[0m (12.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ✅ Importar librerías necesarias\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model, Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ✅ Rutas de los archivos\n",
    "ruta_test_csv = r'C:\\Users\\mikel\\OneDrive\\Documentos\\TB-DS-BIO-23.09.24\\REPOSITORIOS\\Mikel\\clip_count\\test.csv'\n",
    "ruta_test_img = r'C:\\Users\\mikel\\OneDrive\\Documentos\\TB-DS-BIO-23.09.24\\REPOSITORIOS\\Mikel\\clip_count\\test'\n",
    "ruta_modelo = r'C:\\Users\\mikel\\OneDrive\\Documentos\\TB-DS-BIO-23.09.24\\REPOSITORIOS\\Mikel\\dsft2409_mikeltelo\\PROJECTS\\kaggle_clip_counting\\modelo_final\\modelo_clip_count_p.h5'\n",
    "ruta_resultados = r'C:\\Users\\mikel\\OneDrive\\Documentos\\TB-DS-BIO-23.09.24\\REPOSITORIOS\\Mikel\\dsft2409_mikeltelo\\PROJECTS\\kaggle_clip_counting\\submission_p_final.csv'\n",
    "\n",
    "# ✅ Cargar el modelo base\n",
    "modelo_base = load_model(ruta_modelo)\n",
    "print(f\"✅ Modelo base cargado correctamente desde '{ruta_modelo}'\")\n",
    "\n",
    "# ✅ Inspeccionar si el modelo es Sequential\n",
    "if isinstance(modelo_base, Sequential):\n",
    "    print(\"🔄 El modelo base es Sequential. Añadiendo entrada explícita.\")\n",
    "    entrada = Input(shape=(128, 128, 1))  # Ajusta la forma si es diferente\n",
    "    x = modelo_base(entrada, training=False)  # Pasamos la entrada explícita\n",
    "else:\n",
    "    print(\"🔄 El modelo base es Functional.\")\n",
    "    entrada = modelo_base.input\n",
    "    x = modelo_base.output\n",
    "\n",
    "# ✅ Congelar capas base\n",
    "for capa in modelo_base.layers:\n",
    "    capa.trainable = False\n",
    "\n",
    "# ✅ Añadir capas personalizadas\n",
    "if len(x.shape) == 4:\n",
    "    print(\"🔄 Salida con 4 dimensiones, aplicando GlobalAveragePooling2D.\")\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "elif len(x.shape) == 2:\n",
    "    print(\"🔄 Salida con 2 dimensiones, aplicando capa Dense directamente.\")\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "else:\n",
    "    raise ValueError(\"❌ Dimensiones de salida inesperadas. Revisa el modelo base.\")\n",
    "\n",
    "# ✅ Capas adicionales\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "salida = Dense(1, activation='linear')(x)  # Salida para regresión\n",
    "\n",
    "# ✅ Crear nuevo modelo funcional\n",
    "modelo_transfer = Model(inputs=entrada, outputs=salida)\n",
    "\n",
    "# ✅ Compilar el modelo\n",
    "modelo_transfer.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                        loss='mean_squared_error',\n",
    "                        metrics=['mean_absolute_error'])\n",
    "\n",
    "# ✅ Mostrar resumen\n",
    "print(\"✅ Modelo ajustado para Transfer Learning listo para ser entrenado.\")\n",
    "modelo_transfer.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Datos de prueba preparados correctamente.\n"
     ]
    }
   ],
   "source": [
    "# ✅ Cargar datos de prueba\n",
    "df_test = pd.read_csv(ruta_test_csv)\n",
    "\n",
    "# ✅ Función de preprocesamiento para imágenes de prueba\n",
    "IMG_SIZE = (128, 128)\n",
    "BATCH_SIZE = 32\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "def cargar_datos_test(df, ruta_img):\n",
    "    ids = df['id'].values\n",
    "    \n",
    "    def preprocesar_imagen(id):\n",
    "        img_path = tf.strings.join([ruta_img, \"/clips-\", tf.strings.as_string(id), \".png\"])\n",
    "        img = tf.io.read_file(img_path)\n",
    "        img = tf.image.decode_png(img, channels=1)\n",
    "        img = tf.image.resize(img, IMG_SIZE)\n",
    "        img = img / 255.0\n",
    "        return img\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices(ids)\n",
    "    dataset = dataset.map(lambda id: preprocesar_imagen(id), num_parallel_calls=AUTOTUNE)\n",
    "    dataset = dataset.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "# ✅ Crear Dataset de Prueba\n",
    "dataset_test = cargar_datos_test(df_test, ruta_test_img)\n",
    "print(\"✅ Datos de prueba preparados correctamente.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Datasets de entrenamiento y validación preparados correctamente.\n"
     ]
    }
   ],
   "source": [
    "# ✅ Importar librerías necesarias\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ✅ Parámetros globales\n",
    "IMG_SIZE = (128, 128)\n",
    "BATCH_SIZE = 32\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# ✅ Rutas de los archivos\n",
    "ruta_train_csv = r'C:\\Users\\mikel\\OneDrive\\Documentos\\TB-DS-BIO-23.09.24\\REPOSITORIOS\\Mikel\\clip_count\\train.csv'\n",
    "ruta_test_img = r'C:\\Users\\mikel\\OneDrive\\Documentos\\TB-DS-BIO-23.09.24\\REPOSITORIOS\\Mikel\\clip_count\\test'\n",
    "\n",
    "# ✅ Cargar datos\n",
    "df = pd.read_csv(ruta_train_csv)\n",
    "\n",
    "# ✅ Dividir en entrenamiento (80%) y validación (20%)\n",
    "df_train, df_val = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# ✅ Función de preprocesamiento para imágenes\n",
    "def cargar_datos(df, ruta_img):\n",
    "    ids = df['id'].values\n",
    "    etiquetas = df['clip_count'].values  # Ajusta si la columna tiene otro nombre\n",
    "\n",
    "    def preprocesar_imagen(id, etiqueta):\n",
    "        img_path = tf.strings.join([ruta_img, \"/clips-\", tf.strings.as_string(id), \".png\"])\n",
    "        img = tf.io.read_file(img_path)\n",
    "        try:\n",
    "            img = tf.image.decode_png(img, channels=1)\n",
    "        except tf.errors.InvalidArgumentError:\n",
    "            print(f\"❌ Error al decodificar la imagen {img_path}\")\n",
    "            img = tf.zeros((IMG_SIZE[0], IMG_SIZE[1], 1))\n",
    "        img = tf.image.resize(img, IMG_SIZE)\n",
    "        img = img / 255.0\n",
    "        return img, etiqueta\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((ids, etiquetas))\n",
    "    dataset = dataset.map(lambda id, etiqueta: preprocesar_imagen(id, etiqueta), num_parallel_calls=AUTOTUNE)\n",
    "    dataset = dataset.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "# ✅ Crear Dataset de Entrenamiento y Validación\n",
    "dataset_train = cargar_datos(df_train, ruta_test_img)\n",
    "dataset_val = cargar_datos(df_val, ruta_test_img)\n",
    "\n",
    "print(\"✅ Datasets de entrenamiento y validación preparados correctamente.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 60ms/step\n",
      "✅ Predicciones generadas correctamente.\n"
     ]
    }
   ],
   "source": [
    "# ✅ Generar predicciones\n",
    "predicciones = modelo_transfer.predict(dataset_test).flatten()\n",
    "df_test['clip_count'] = np.round(predicciones).astype(int)\n",
    "print(\"✅ Predicciones generadas correctamente.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 **Métricas del Modelo en el Conjunto de Prueba:**\n",
      "✅ MAE (Error Absoluto Medio): 0.00\n",
      "✅ MSE (Error Cuadrático Medio): 0.00\n",
      "✅ RMSE (Raíz del Error Cuadrático Medio): 0.00\n",
      "✅ R2 Score (Coeficiente de Determinación): 1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# ✅ Comprobar si existen etiquetas reales en el dataset de prueba\n",
    "if 'clip_count' in df_test.columns:\n",
    "    etiquetas_reales = df_test['clip_count'].values\n",
    "    etiquetas_predichas = np.round(predicciones).astype(int)\n",
    "    \n",
    "    # ✅ Calcular Métricas\n",
    "    mae = mean_absolute_error(etiquetas_reales, etiquetas_predichas)\n",
    "    mse = mean_squared_error(etiquetas_reales, etiquetas_predichas)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(etiquetas_reales, etiquetas_predichas)\n",
    "    \n",
    "    # ✅ Mostrar Métricas\n",
    "    print(\"📊 **Métricas del Modelo en el Conjunto de Prueba:**\")\n",
    "    print(f\"✅ MAE (Error Absoluto Medio): {mae:.2f}\")\n",
    "    print(f\"✅ MSE (Error Cuadrático Medio): {mse:.2f}\")\n",
    "    print(f\"✅ RMSE (Raíz del Error Cuadrático Medio): {rmse:.2f}\")\n",
    "    print(f\"✅ R2 Score (Coeficiente de Determinación): {r2:.2f}\")\n",
    "else:\n",
    "    print(\"❌ El conjunto de prueba no contiene etiquetas reales ('clip_count'). No se pueden calcular métricas.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Archivo de salida guardado en 'C:\\Users\\mikel\\OneDrive\\Documentos\\TB-DS-BIO-23.09.24\\REPOSITORIOS\\Mikel\\dsft2409_mikeltelo\\PROJECTS\\kaggle_clip_counting\\submission_p_final_tl.csv'\n",
      "📊 **Vista previa del archivo de salida:**\n",
      "      id  clip_count\n",
      "0  45001           5\n",
      "1  45002           3\n",
      "2  45003           3\n",
      "3  45004           3\n",
      "4  45005           1\n"
     ]
    }
   ],
   "source": [
    "# ✅ Crear un DataFrame con las Predicciones\n",
    "df_resultados = pd.DataFrame({\n",
    "    'id': df_test['id'],  # Usamos los IDs del archivo original\n",
    "    'clip_count': np.round(predicciones).astype(int)  # Redondeamos las predicciones\n",
    "})\n",
    "\n",
    "# ✅ Guardar en un Archivo CSV\n",
    "ruta_salida = r'C:\\Users\\mikel\\OneDrive\\Documentos\\TB-DS-BIO-23.09.24\\REPOSITORIOS\\Mikel\\dsft2409_mikeltelo\\PROJECTS\\kaggle_clip_counting\\submission_p_final_tl.csv'\n",
    "df_resultados.to_csv(ruta_salida, index=False)\n",
    "\n",
    "print(f\"✅ Archivo de salida guardado en '{ruta_salida}'\")\n",
    "print(\"📊 **Vista previa del archivo de salida:**\")\n",
    "print(df_resultados.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
