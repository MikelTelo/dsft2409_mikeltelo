{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Manipulación de Datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ✅ TensorFlow y Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# ✅ Visualización\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Rutas de los archivos\n",
    "ruta_train_csv = r'C:\\Users\\mikel\\OneDrive\\Documentos\\TB-DS-BIO-23.09.24\\REPOSITORIOS\\Mikel\\clip_count\\train.csv'\n",
    "ruta_train_img = r'C:\\Users\\mikel\\OneDrive\\Documentos\\TB-DS-BIO-23.09.24\\REPOSITORIOS\\Mikel\\clip_count\\train'\n",
    "ruta_test_csv = r'C:\\Users\\mikel\\OneDrive\\Documentos\\TB-DS-BIO-23.09.24\\REPOSITORIOS\\Mikel\\clip_count\\test.csv'\n",
    "ruta_test_img = r'C:\\Users\\mikel\\OneDrive\\Documentos\\TB-DS-BIO-23.09.24\\REPOSITORIOS\\Mikel\\clip_count\\test'\n",
    "ruta_modelo = r'C:\\Users\\mikel\\OneDrive\\Documentos\\TB-DS-BIO-23.09.24\\REPOSITORIOS\\Mikel\\dsft2409_mikeltelo\\PROJECTS\\kaggle_clip_counting\\modelo_final\\modelo_clip_count_p.h5'\n",
    "ruta_resultados = r'C:\\Users\\mikel\\OneDrive\\Documentos\\TB-DS-BIO-23.09.24\\REPOSITORIOS\\Mikel\\dsft2409_mikeltelo\\PROJECTS\\kaggle_clip_counting\\submission_p_final.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CSVs cargados y validados correctamente.\n"
     ]
    }
   ],
   "source": [
    "# ✅ Cargar archivos CSV\n",
    "df_train = pd.read_csv(ruta_train_csv)\n",
    "df_test = pd.read_csv(ruta_test_csv)\n",
    "\n",
    "# ✅ Validar columnas\n",
    "assert 'id' in df_train.columns, \"❌ 'train.csv' debe tener una columna llamada 'id'.\"\n",
    "assert 'clip_count' in df_train.columns, \"❌ 'train.csv' debe tener una columna llamada 'clip_count'.\"\n",
    "assert 'id' in df_test.columns, \"❌ 'test.csv' debe tener una columna llamada 'id'.\"\n",
    "\n",
    "# ✅ Eliminar valores nulos\n",
    "df_train = df_train.dropna(subset=['id', 'clip_count'])\n",
    "df_test = df_test.dropna(subset=['id'])\n",
    "\n",
    "print(\"✅ CSVs cargados y validados correctamente.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ IDs validados con imágenes existentes.\n"
     ]
    }
   ],
   "source": [
    "# ✅ Filtrar imágenes existentes\n",
    "def filtrar_ids_con_imagenes(df, ruta_img):\n",
    "    ids_validos = []\n",
    "    for img_id in df['id']:\n",
    "        img_path = os.path.join(ruta_img, f\"clips-{img_id}.png\")\n",
    "        if os.path.exists(img_path):\n",
    "            ids_validos.append(img_id)\n",
    "        else:\n",
    "            print(f\"❌ Imagen no encontrada: {img_path}\")\n",
    "    return df[df['id'].isin(ids_validos)]\n",
    "\n",
    "df_train = filtrar_ids_con_imagenes(df_train, ruta_train_img)\n",
    "df_test = filtrar_ids_con_imagenes(df_test, ruta_test_img)\n",
    "\n",
    "print(\"✅ IDs validados con imágenes existentes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Datasets creados correctamente.\n"
     ]
    }
   ],
   "source": [
    "# ✅ Parámetros de imágenes\n",
    "IMG_SIZE = (128, 128)\n",
    "BATCH_SIZE = 32\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# ✅ Función para cargar datos\n",
    "def cargar_datos(df, ruta_img, objetivo=None):\n",
    "    ids = df['id'].values\n",
    "    objetivos = df[objetivo].values if objetivo else None\n",
    "    \n",
    "    def preprocesar_imagen(id, objetivo=None):\n",
    "        img_path = tf.strings.join([ruta_img, \"/clips-\", tf.strings.as_string(id), \".png\"])\n",
    "        img = tf.io.read_file(img_path)\n",
    "        img = tf.image.decode_png(img, channels=1)\n",
    "        img = tf.image.resize(img, IMG_SIZE)\n",
    "        img = img / 255.0\n",
    "        \n",
    "        if objetivo is not None:\n",
    "            return img, objetivo\n",
    "        return img\n",
    "    \n",
    "    if objetivo is not None:\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((ids, objetivos))\n",
    "        dataset = dataset.map(lambda id, objetivo: preprocesar_imagen(id, objetivo), num_parallel_calls=AUTOTUNE)\n",
    "    else:\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(ids)\n",
    "        dataset = dataset.map(lambda id: preprocesar_imagen(id), num_parallel_calls=AUTOTUNE)\n",
    "    \n",
    "    dataset = dataset.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "# ✅ Dividir datos\n",
    "df_train, df_val = train_test_split(df_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# ✅ Crear datasets\n",
    "dataset_train = cargar_datos(df_train, ruta_train_img, objetivo='clip_count')\n",
    "dataset_val = cargar_datos(df_val, ruta_train_img, objetivo='clip_count')\n",
    "dataset_test = cargar_datos(df_test, ruta_test_img)\n",
    "\n",
    "print(\"✅ Datasets creados correctamente.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# ✅ Cargar modelo\n",
    "modelo = load_model(ruta_modelo)\n",
    "\n",
    "# ✅ Descongelar capas finales\n",
    "for capa in modelo.layers[-10:]:\n",
    "    capa.trainable = True\n",
    "\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "\n",
    "# ✅ Compilar el modelo con la métrica correcta\n",
    "modelo.compile(\n",
    "    optimizer=Adam(learning_rate=1e-4),\n",
    "    loss='mean_squared_error',\n",
    "    metrics=[RootMeanSquaredError(name='rmse')]  # Corregido\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Callbacks\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'modelo_clip_count_reentrenado_v2.keras',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 338ms/step - loss: 77.9774 - rmse: 8.8300 - val_loss: 5.7521 - val_rmse: 2.3984\n",
      "Epoch 2/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 325ms/step - loss: 74.3590 - rmse: 8.6221 - val_loss: 4.3148 - val_rmse: 2.0772\n",
      "Epoch 3/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 338ms/step - loss: 75.8144 - rmse: 8.7056 - val_loss: 23.8159 - val_rmse: 4.8802\n",
      "Epoch 4/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 323ms/step - loss: 74.7380 - rmse: 8.6443 - val_loss: 6.8686 - val_rmse: 2.6208\n",
      "Epoch 5/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 324ms/step - loss: 75.9204 - rmse: 8.7125 - val_loss: 12.3586 - val_rmse: 3.5155\n",
      "Epoch 6/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 329ms/step - loss: 75.6601 - rmse: 8.6970 - val_loss: 4.9230 - val_rmse: 2.2188\n",
      "Epoch 7/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 333ms/step - loss: 72.1044 - rmse: 8.4879 - val_loss: 4.0348 - val_rmse: 2.0087\n",
      "Epoch 8/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 333ms/step - loss: 74.1687 - rmse: 8.6106 - val_loss: 22.5625 - val_rmse: 4.7500\n",
      "Epoch 9/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 319ms/step - loss: 72.7905 - rmse: 8.5274 - val_loss: 4.3081 - val_rmse: 2.0756\n",
      "Epoch 10/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 319ms/step - loss: 74.7946 - rmse: 8.6459 - val_loss: 5.6018 - val_rmse: 2.3668\n",
      "Epoch 11/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 325ms/step - loss: 72.3106 - rmse: 8.5030 - val_loss: 6.6502 - val_rmse: 2.5788\n",
      "Epoch 12/15\n",
      "\u001b[1m130/375\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:19\u001b[0m 325ms/step - loss: 70.7590 - rmse: 8.4028"
     ]
    }
   ],
   "source": [
    "# ✅ Entrenamiento\n",
    "historial = modelo.fit(\n",
    "    dataset_train,\n",
    "    validation_data=dataset_val,\n",
    "    epochs=15,\n",
    "    callbacks=[early_stopping, checkpoint]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Evaluar\n",
    "resultados = modelo.evaluate(dataset_val)\n",
    "print(\"✅ Resultados en validación:\", resultados)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Generar predicciones\n",
    "predicciones = modelo.predict(dataset_test).flatten()\n",
    "df_test['clip_count'] = np.round(predicciones).astype(int)\n",
    "\n",
    "# ✅ Guardar predicciones\n",
    "df_test[['id', 'clip_count']].to_csv(ruta_resultados, index=False)\n",
    "print(f\"✅ Archivo de predicciones guardado en '{ruta_resultados}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
