{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip uninstall -y tensorflow tensorflow-intel tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip uninstall -y tensorflow-io-gcs-filesystem 0.31.0\n",
    "#!pip uninstall -y tensorflow-estimator         2.13.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip cache purge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow==2.15.0 --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip list | findstr tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå No se encontr√≥ GPU. Usando CPU.\n"
     ]
    }
   ],
   "source": [
    "# üìö IMPORTAR LIBRER√çAS PRINCIPALES\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# ‚öôÔ∏è CONFIGURAR USO DE GPU\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Configurar solo la primera GPU\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "        tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "        print(\"‚úÖ GPU configurada correctamente.\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"‚ùå No se encontr√≥ GPU. Usando CPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìö Librer√≠as Necesarias\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "# ‚úÖ Par√°metros Globales\n",
    "IMG_SIZE = (128, 128)  # Tama√±o de las im√°genes\n",
    "BATCH_SIZE = 32        # Tama√±o del batch\n",
    "EPOCHS = 50            # N√∫mero de √©pocas\n",
    "COLOR_MODE = 'grayscale'  # Im√°genes en escala de grises\n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Rutas de Datos\n",
    "ruta_train_csv = r'D:\\Archivos de usuarios\\Mikel Telo\\OneDrive\\Documentos\\TB-DS-BIO-23.09.24\\REPOSITORIOS\\Mikel\\clip_count\\train.csv'\n",
    "ruta_test_csv = r'D:\\Archivos de usuarios\\Mikel Telo\\OneDrive\\Documentos\\TB-DS-BIO-23.09.24\\REPOSITORIOS\\Mikel\\clip_count\\test.csv'\n",
    "ruta_train_img = r'D:\\Archivos de usuarios\\Mikel Telo\\OneDrive\\Documentos\\TB-DS-BIO-23.09.24\\REPOSITORIOS\\Mikel\\clip_count\\train'\n",
    "ruta_test_img = r'D:\\Archivos de usuarios\\Mikel Telo\\OneDrive\\Documentos\\TB-DS-BIO-23.09.24\\REPOSITORIOS\\Mikel\\clip_count\\test'\n",
    "\n",
    "# ‚úÖ Cargar Datos\n",
    "df_train = pd.read_csv(ruta_train_csv)\n",
    "df_test = pd.read_csv(ruta_test_csv)\n",
    "\n",
    "# ‚úÖ Preprocesamiento de Im√°genes\n",
    "def cargar_datos(df, ruta_img, es_entrenamiento=True):\n",
    "    ids = df['id'].values\n",
    "    labels = df['clip_count'].values if 'clip_count' in df.columns else None\n",
    "    \n",
    "    def preprocesar_imagen(id, label=None):\n",
    "        img_path = tf.strings.join([ruta_img, \"/clips-\", tf.strings.as_string(id), \".png\"])\n",
    "        img = tf.io.read_file(img_path)\n",
    "        img = tf.image.decode_png(img, channels=1)\n",
    "        img = tf.image.resize(img, IMG_SIZE)\n",
    "        img = img / 255.0\n",
    "        return (img, tf.cast(label, tf.float32)) if label is not None else img\n",
    "    \n",
    "    if es_entrenamiento:\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((ids, labels))\n",
    "        dataset = dataset.map(lambda id, label: preprocesar_imagen(id, label), num_parallel_calls=AUTOTUNE)\n",
    "    else:\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(ids)\n",
    "        dataset = dataset.map(lambda id: preprocesar_imagen(id), num_parallel_calls=AUTOTUNE)\n",
    "    \n",
    "    dataset = dataset.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "# ‚úÖ Crear Datasets\n",
    "df_train, df_val = train_test_split(df_train, test_size=0.2, random_state=42)\n",
    "dataset_train = cargar_datos(df_train, ruta_train_img, es_entrenamiento=True)\n",
    "dataset_val = cargar_datos(df_val, ruta_train_img, es_entrenamiento=True)\n",
    "dataset_test = cargar_datos(df_test, ruta_test_img, es_entrenamiento=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\mikel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\mikel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 126, 126, 32)      320       \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 126, 126, 32)      128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 63, 63, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 61, 61, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 61, 61, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 30, 30, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 28, 28, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 28, 28, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 14, 14, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               6422784   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6516609 (24.86 MB)\n",
      "Trainable params: 6516161 (24.86 MB)\n",
      "Non-trainable params: 448 (1.75 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Definir el Modelo CNN\n",
    "def crear_modelo():\n",
    "    modelo = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 1)),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        \n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        \n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        \n",
    "        Flatten(),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='linear')  # Salida de regresi√≥n\n",
    "    ])\n",
    "    \n",
    "    modelo.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='mean_squared_error',\n",
    "        metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')]\n",
    "    )\n",
    "    return modelo\n",
    "\n",
    "# ‚úÖ Crear Modelo\n",
    "modelo = crear_modelo()\n",
    "modelo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:From c:\\Users\\mikel\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      " 27/375 [=>............................] - ETA: 5:59 - loss: 1478.6875 - rmse: 38.4537"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Callbacks\n",
    "early_stop = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(factor=0.5, patience=5)\n",
    "\n",
    "# ‚úÖ Entrenar Modelo\n",
    "historial = modelo.fit(\n",
    "    dataset_train,\n",
    "    validation_data=dataset_val,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[early_stop, reduce_lr]\n",
    ")\n",
    "\n",
    "# ‚úÖ Graficar M√©tricas\n",
    "plt.plot(historial.history['rmse'], label='RMSE (Train)')\n",
    "plt.plot(historial.history['val_rmse'], label='RMSE (Validation)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Evaluaci√≥n\n",
    "train_loss, train_rmse = modelo.evaluate(dataset_train)\n",
    "val_loss, val_rmse = modelo.evaluate(dataset_val)\n",
    "print(f\"üîπ RMSE (Train): {train_rmse:.2f}\")\n",
    "print(f\"üîπ RMSE (Validation): {val_rmse:.2f}\")\n",
    "\n",
    "# ‚úÖ Predicciones\n",
    "predicciones = modelo.predict(dataset_test).flatten()\n",
    "df_test['clip_count'] = np.round(predicciones).astype(int)\n",
    "\n",
    "# ‚úÖ Guardar Resultados\n",
    "df_test[['id', 'clip_count']].to_csv('submission_p.csv', index=False)\n",
    "print(\"‚úÖ Archivo 'submission_p.csv' generado correctamente.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
