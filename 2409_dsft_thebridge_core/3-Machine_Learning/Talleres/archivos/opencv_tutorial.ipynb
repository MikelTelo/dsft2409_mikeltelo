{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TUTORIAL DE OPENCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LIBRERÍAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CARGA DE IMÁGENES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('./Resources/Photos/cats.jpg')\n",
    "\n",
    "cv.imshow('Cats', img) # Muestra la imagen.\n",
    "\n",
    "cv.waitKey(0) # Necesitamos poner esta línea para indicarle que se cierre la ventana emergente manualmente sin que dé error en el notebook.\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "# Cuando usamos un script de python en lugar de un notebook, funciona del siguiente modo:\n",
    "# - El valor 0 indicará que la ventana no se cierra hasta que no lo hagamos manualmente o presionemos una tecla\n",
    "# - Un valor mayor que 0, indicará los milisegundos que permanecerá abierta la ventana.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv.cvtColor(img, cv.COLOR_BGR2RGB));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CARGA DE VÍDEOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv.VideoCapture('./Resources/Videos/dog.mp4') # creamos el capturador de frames\n",
    "\n",
    "while True:\n",
    "    isTrue, frame = capture.read() \n",
    "    \n",
    "    if isTrue:\n",
    "        cv.imshow('Video', frame)\n",
    "        if cv.waitKey(20) & 0xFF==ord('c'): # permite salir del bucle pulsando la tecla 'c'\n",
    "            break            \n",
    "    else:\n",
    "        break\n",
    "\n",
    "capture.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar la imagen o vídeo\n",
    "\n",
    "cv.imwrite(\"output.jpg\", img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FUNCIONES BÁSICAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sacar contornos. Es una de las funciones más útiles a la hora de crear modelos de Machine Learning para la detección y/o identificación de objetos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imshow('img', img)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canny = cv.Canny(img, 125, 175)\n",
    "cv.imshow('Canny Edges', canny)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contours, hierarchies = cv.findContours(canny, cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE)\n",
    "print(f'{len(contours)} contour(s) found!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos demasiados contornos para que un modelo de Machine Learning pueda ser bien entrenado. Para solucionar esto, podemos reducir la información que contiene del siguiente modo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertir a escala de grises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "cv.imshow('Gray', gray)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canny = cv.Canny(gray, 125, 175)\n",
    "cv.imshow('Canny Edges', canny)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contours, hierarchies = cv.findContours(canny, cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE)\n",
    "print(f'{len(contours)} contour(s) found!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacer la imagen más borrosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blur = cv.GaussianBlur(img, (7,7), cv.BORDER_DEFAULT)\n",
    "cv.imshow('Blur', blur)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canny = cv.Canny(blur, 125, 175)\n",
    "cv.imshow('Canny Edges', canny)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contours, hierarchies = cv.findContours(canny, cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE)\n",
    "print(f'{len(contours)} contour(s) found!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expandir la imagen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El proceso de dilatación consiste en expandir las regiones blancas (píxeles con valor alto) en una imagen binaria para resaltar características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dilated = cv.dilate(canny, (7,7), iterations=3)\n",
    "cv.imshow('Dilated', dilated)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reducir la imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eroded = cv.erode(dilated, (7,7), iterations=3)\n",
    "cv.imshow('Eroded', eroded)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redimensionar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized = cv.resize(img, (500,500), interpolation=cv.INTER_CUBIC)\n",
    "cv.imshow('Resized', resized)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagen espejo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flip = cv.flip(img, -1)\n",
    "cv.imshow('Flip', flip)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rotar imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate(img, angle, rotPoint=None):\n",
    "    (height,width) = img.shape[:2]\n",
    "\n",
    "    if rotPoint is None:\n",
    "        rotPoint = (width//2,height//2)\n",
    "    \n",
    "    rotMat = cv.getRotationMatrix2D(rotPoint, angle, 1.0)\n",
    "    dimensions = (width,height)\n",
    "\n",
    "    return cv.warpAffine(img, rotMat, dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotated = rotate(img, -45)\n",
    "cv.imshow('Rotated', rotated)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trasladar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(img, x, y):\n",
    "    transMat = np.float32([[1,0,x],[0,1,y]])\n",
    "    dimensions = (img.shape[1], img.shape[0])\n",
    "    return cv.warpAffine(img, transMat, dimensions)\n",
    "\n",
    "# -x --> Left\n",
    "# -y --> Up\n",
    "# x --> Right\n",
    "# y --> Down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translated = translate(img, -100, 100)\n",
    "cv.imshow('Translated', translated)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostrar una región determinada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped = img[50:200, 200:400]\n",
    "cv.imshow('Cropped', cropped)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DIBUJAR EN UNA IMAGEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear imagen \"vacía\" con dimensiones determinadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blank = np.zeros(img.shape, dtype='uint8')\n",
    "cv.imshow('Blank', blank)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blank = np.zeros((500,500,3), dtype='uint8')\n",
    "cv.imshow('Blank', blank)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto es muy útil para eliminar información innecesaria. Así, por ejemplo, podemos detectar los contornos de los gatos y dibujarlos en nuestra imagen vacía. De este modo, aligeramos mucho la imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.drawContours(blank, contours, -1, (0,0,255), 1)\n",
    "\n",
    "cv.imshow('Contours Drawn', blank)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n",
    "cv.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otros tipos de dibujos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Pintar la imagen de cierto color\n",
    "blank[200:300, 300:400] = 0,0,255\n",
    "cv.imshow('Red', blank)\n",
    "\n",
    "# 2. Dibujar un rectángulo\n",
    "cv.rectangle(blank, (0,0), (blank.shape[1]//2, blank.shape[0]//2), (0,255,0), thickness=-1)\n",
    "cv.imshow('Rectangle', blank)\n",
    "\n",
    "# 3. Dibujar un círculo\n",
    "cv.circle(blank, (blank.shape[1]//2, blank.shape[0]//2), 40, (0,0,255), thickness=-1)\n",
    "cv.imshow('Circle', blank)\n",
    "\n",
    "# 4. Dibujar una línea\n",
    "cv.line(blank, (100,250), (300,400), (255,255,255), thickness=3)\n",
    "cv.imshow('Line', blank)\n",
    "\n",
    "# 5. Escribir texto\n",
    "cv.putText(blank, 'Hola mundo', (0,225), cv.FONT_HERSHEY_TRIPLEX, 1.0, (255,0,0), 2)\n",
    "cv.imshow('Text', blank)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OTRAS FUNCIONES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagen bicolor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desde una imagen en escala de grises, podemos sacar una imagen bicolor. Establecemos un valor de referencia o thresh, y todos los valores por encima de éste serán el valor máximo (también establecido) y los que estén por debajo serán 0. Con esto también eliminamos mucha información innecesaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thresholding simple\n",
    "threshold, thresh = cv.threshold(gray, 150, 255, cv.THRESH_BINARY )\n",
    "cv.imshow('Simple Thresholded', thresh)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold, thresh_inv = cv.threshold(gray, 150, 255, cv.THRESH_BINARY_INV )\n",
    "cv.imshow('Simple Thresholded Inverse', thresh_inv)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thresholding adaptativo\n",
    "adaptive_thresh = cv.adaptiveThreshold(gray, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY_INV, 11, 9)\n",
    "cv.imshow('Adaptive Thresholding', adaptive_thresh)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Espacios de color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('./Resources/Photos/park.jpg')\n",
    "cv.imshow('Park', img)\n",
    "\n",
    "# Color a escala de grises\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "cv.imshow('Gray', gray)\n",
    "\n",
    "# BGR a HSV. Modelo de color HSV (Hue, Saturation, Value – Tonalidad, Saturación, Brillo)\n",
    "hsv = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
    "cv.imshow('HSV', hsv)\n",
    "\n",
    "# BGR a LAB (L*a*b) (L*=luminosidad, a*= coordenadas rojo/verde (+a indica rojo, -a indica verde), b* = coordenadas amarillo/azul (+b indica amarillo, -b indica azul))\n",
    "lab = cv.cvtColor(img, cv.COLOR_BGR2LAB)\n",
    "cv.imshow('LAB', lab)\n",
    "\n",
    "# BGR a RGB\n",
    "rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "cv.imshow('RGB', rgb)\n",
    "\n",
    "# LAB a BGR\n",
    "lab_bgr = cv.cvtColor(lab, cv.COLOR_LAB2BGR)\n",
    "cv.imshow('LAB --> BGR', lab_bgr)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradientes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image alt text](https://docs.opencv.org/4.x/gradients.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('./Resources/Photos/park.jpg')\n",
    "cv.imshow('Park', img)\n",
    "\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "cv.imshow('Gray', gray)\n",
    "\n",
    "# Sobel \n",
    "sobelx = cv.Sobel(gray, cv.CV_64F, 1, 0)\n",
    "sobely = cv.Sobel(gray, cv.CV_64F, 0, 1)\n",
    "combined_sobel = cv.bitwise_or(sobelx, sobely)\n",
    "\n",
    "# Laplacian\n",
    "lap = cv.Laplacian(gray, cv.CV_64F)\n",
    "lap = np.uint8(np.absolute(lap))\n",
    "cv.imshow('Laplacian', lap)\n",
    "\n",
    "cv.imshow('Sobel X', sobelx)\n",
    "cv.imshow('Sobel Y', sobely)\n",
    "cv.imshow('Combined Sobel', combined_sobel)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Máscaras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://omes-va.com/operadores-bitwise/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bitwise_and: devuelve 1 o verdadero cuando todas sus entradas eran 1 o verdaderas. Es decir, coge las regiones comunes con la primera imagen y la segunda.\n",
    "\n",
    "![image alt text](https://omes-va.com/wp-content/uploads/2019/10/TABLA-DE-VERDAD-AND.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('./Resources/Photos/cats 2.jpg')\n",
    "cv.imshow('Cats', img)\n",
    "\n",
    "blank = np.zeros(img.shape[:2], dtype='uint8')\n",
    "cv.imshow('Blank Image', blank)\n",
    "\n",
    "circle = cv.circle(blank.copy(), (img.shape[1]//2 + 45,img.shape[0]//2), 100, 255, -1)\n",
    "\n",
    "rectangle = cv.rectangle(blank.copy(), (30,30), (370,370), 255, -1)\n",
    "\n",
    "weird_shape = cv.bitwise_and(circle,rectangle)\n",
    "cv.imshow('Weird Shape', weird_shape)\n",
    "\n",
    "masked = cv.bitwise_and(img,img,mask=weird_shape)\n",
    "cv.imshow('Weird Shaped Masked Image', masked)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bitwise_or: al menos uno de los valores de entrada es verdadero o 1, su salida también lo es. Es únicamente falso o 0, cuando todas sus entradas son 0 o falso. Es decir,coge las regiones que están definidas por la primera imagen o la segunda.\n",
    "\n",
    "![image alt text](https://omes-va.com/wp-content/uploads/2019/10/TABLA-DE-VERDAD-OR.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('./Resources/Photos/cats 2.jpg')\n",
    "cv.imshow('Cats', img)\n",
    "\n",
    "blank = np.zeros(img.shape[:2], dtype='uint8')\n",
    "cv.imshow('Blank Image', blank)\n",
    "\n",
    "circle = cv.circle(blank.copy(), (img.shape[1]//2 + 45,img.shape[0]//2), 100, 255, -1)\n",
    "\n",
    "rectangle = cv.rectangle(blank.copy(), (30,30), (370,370), 255, -1)\n",
    "\n",
    "weird_shape = cv.bitwise_or(circle,rectangle)\n",
    "cv.imshow('Weird Shape', weird_shape)\n",
    "\n",
    "masked = cv.bitwise_and(img,img,mask=weird_shape)\n",
    "cv.imshow('Weird Shaped Masked Image', masked)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bitwise_xor: sus salidas toman el valor de falso o 0 cuando ambas entradas poseen el mismo valor, mientras que es verdadero o 1 en los demás casos. Es decir, coge las regiones que no sean comunes a las dos imágenes.\n",
    "\n",
    "![image alt text](https://omes-va.com/wp-content/uploads/2019/10/TABLA-DE-VERDAD-XOR.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('./Resources/Photos/cats 2.jpg')\n",
    "cv.imshow('Cats', img)\n",
    "\n",
    "blank = np.zeros(img.shape[:2], dtype='uint8')\n",
    "cv.imshow('Blank Image', blank)\n",
    "\n",
    "circle = cv.circle(blank.copy(), (img.shape[1]//2 + 45,img.shape[0]//2), 100, 255, -1)\n",
    "\n",
    "rectangle = cv.rectangle(blank.copy(), (30,30), (370,370), 255, -1)\n",
    "\n",
    "weird_shape = cv.bitwise_xor(circle,rectangle)\n",
    "cv.imshow('Weird Shape', weird_shape)\n",
    "\n",
    "masked = cv.bitwise_and(img,img,mask=weird_shape)\n",
    "cv.imshow('Weird Shaped Masked Image', masked)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bitwise_not: cuando una entrada es verdadera o 1, su salida es falso o  0, y viceversa. Es decir, devuelve los valores contrarios de la imagen dada (ya que admite darle solo una imagen) o lo no común entre la primera imagen y la segunda, incluidos los colores, por lo que devolverá los colores negativos.\n",
    "\n",
    "![image alt text](https://omes-va.com/wp-content/uploads/2019/10/TABLA-DE-VERDAD-NOT.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('./Resources/Photos/cats 2.jpg')\n",
    "cv.imshow('Cats', img)\n",
    "\n",
    "blank = np.zeros(img.shape[:2], dtype='uint8')\n",
    "cv.imshow('Blank Image', blank)\n",
    "\n",
    "circle = cv.circle(blank.copy(), (img.shape[1]//2 + 45,img.shape[0]//2), 100, 255, -1)\n",
    "\n",
    "rectangle = cv.rectangle(blank.copy(), (30,30), (370,370), 255, -1)\n",
    "\n",
    "weird_shape = cv.bitwise_not(circle,rectangle)\n",
    "cv.imshow('Weird Shape', weird_shape)\n",
    "\n",
    "masked = cv.bitwise_not(img,img,mask=weird_shape)\n",
    "cv.imshow('Weird Shaped Masked Image', masked)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('./Resources/Photos/cats.jpg')\n",
    "cv.imshow('Cats', img)\n",
    "\n",
    "blank = np.zeros(img.shape[:2], dtype='uint8')\n",
    "\n",
    "# gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "# cv.imshow('Gray', gray)\n",
    "\n",
    "mask = cv.circle(blank, (img.shape[1]//2,img.shape[0]//2), 100, 255, -1)\n",
    "\n",
    "masked = cv.bitwise_and(img,img,mask=mask)\n",
    "cv.imshow('Mask', masked)\n",
    "\n",
    "# GRayscale histogram\n",
    "# gray_hist = cv.calcHist([gray], [0], mask, [256], [0,256] )\n",
    "\n",
    "# plt.figure()\n",
    "# plt.title('Grayscale Histogram')\n",
    "# plt.xlabel('Bins')\n",
    "# plt.ylabel('# of pixels')\n",
    "# plt.plot(gray_hist)\n",
    "# plt.xlim([0,256])\n",
    "# plt.show()\n",
    "\n",
    "# Colour Histogram\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Colour Histogram')\n",
    "plt.xlabel('Bins')\n",
    "plt.ylabel('# of pixels')\n",
    "colors = ('b', 'g', 'r')\n",
    "for i,col in enumerate(colors):\n",
    "    hist = cv.calcHist([img], [i], mask, [256], [0,256])\n",
    "    plt.plot(hist, color=col)\n",
    "    plt.xlim([0,256])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "División en los canales de color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(427, 640, 3)\n",
      "(427, 640)\n",
      "(427, 640)\n",
      "(427, 640)\n"
     ]
    }
   ],
   "source": [
    "img = cv.imread('./Resources/Photos/park.jpg')\n",
    "cv.imshow('Park', img)\n",
    "\n",
    "blank = np.zeros(img.shape[:2], dtype='uint8')\n",
    "\n",
    "b,g,r = cv.split(img)\n",
    "\n",
    "blue = cv.merge([b,blank,blank])\n",
    "green = cv.merge([blank,g,blank])\n",
    "red = cv.merge([blank,blank,r])\n",
    "\n",
    "\n",
    "cv.imshow('Blue', blue)\n",
    "cv.imshow('Green', green)\n",
    "cv.imshow('Red', red)\n",
    "\n",
    "print(img.shape)\n",
    "print(b.shape)\n",
    "print(g.shape)\n",
    "print(r.shape)\n",
    "\n",
    "merged = cv.merge([b,g,r])\n",
    "cv.imshow('Merged Image', merged)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DETECCIÓN DE ROSTROS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenCV tiene algunos modelos de predicción de Machine Learning preentrenados incorporados. De este modo, podremos, por ejemplo, detectar rostros en una imagen.\n",
    "\n",
    "https://github.com/opencv/opencv/tree/4.x/data/haarcascades\n",
    "\n",
    "En este enlace podemos ver todos los modelos preentrenados de los que disponemos. Para usarlos, tendremos que copiar todo el código *.xml de aquel modelo que queramos usar, crear un archivo con extensión *.xml y copiarlo dentro. De este modo, ya podremos cargar el modelo desde ahí."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of faces found = 1\n"
     ]
    }
   ],
   "source": [
    "# Utilizaremos un modelo en cascada \"CascadeClassifier\", que nos permitirá identificar distintos elementos\n",
    "\n",
    "img = cv.imread('./Resources/Photos/lady.jpg')\n",
    "cv.imshow('Lady', img)\n",
    "\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY) # El modelo en cascada no atiende al tono de la piel, solo a los contornos, por lo que no nos\n",
    "# hace falta el color, que hace que una imagen sea mucho más pesada.\n",
    "cv.imshow('Gray lady', gray)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "haar_cascade = cv.CascadeClassifier('./Resources/Exercise/haarcascade_frontalface_default.xml') # este modelo haar identifica caras que están de frente\n",
    "\n",
    "faces_rect = haar_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5) # Nos devolverá una lista con las coordenadas \n",
    "# rectangulares de cada una de las caras que ha identificado.\n",
    "\n",
    "print(f'Number of faces found = {len(faces_rect)}')\n",
    "\n",
    "for (x,y,w,h) in faces_rect:\n",
    "    cv.rectangle(img, (x,y), (x+w,y+h), (0,255,0), thickness=2) # dibuja el rectángulo en las coordenadas especificadas\n",
    "\n",
    "cv.imshow('Detected Faces', img)\n",
    "\n",
    "\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of faces found = 19\n"
     ]
    }
   ],
   "source": [
    "img = cv.imread('./Resources/Photos/group 1.jpg')\n",
    "cv.imshow('Group of 5 people', img)\n",
    "\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "cv.imshow('Gray People', gray)\n",
    "\n",
    "# haar_cascade = cv.CascadeClassifier('./Section #3 - Faces/haar_face.xml')\n",
    "haar_cascade = cv.CascadeClassifier('./Resources/Exercise/haarcascade_frontalface_default.xml')\n",
    "\n",
    "faces_rect = haar_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=1)\n",
    "\n",
    "print(f'Number of faces found = {len(faces_rect)}')\n",
    "\n",
    "for (x,y,w,h) in faces_rect:\n",
    "    cv.rectangle(img, (x,y), (x+w,y+h), (0,255,0), thickness=2)\n",
    "\n",
    "cv.imshow('Detected Faces', img)\n",
    "\n",
    "\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Referencias:\n",
    "\n",
    "https://www.youtube.com/watch?v=oXlwWbU8l2o&ab_channel=freeCodeCamp.org\n",
    "\n",
    "https://github.com/opencv/opencv\n",
    "\n",
    "https://omes-va.com/operadores-bitwise/\n",
    "\n",
    "https://docs.opencv.org/4.x/d5/d0f/tutorial_py_gradients.html"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "838a4f74a7cbe44792946a8ac940c6fc30bfe72a2fd97b73175a69765affae38"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 ('.venv_opencv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
