{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image cleaning with **OPEN CV**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook he puesto en práctica la herramienta de *computer vision* adaptada para python OPEN-CV. En las siguientes celdas he desarrollado el proceso de encontrar una función capaz de aislar los objetos de las imágenes de forma que sea posible contarlas con un algoritmo de inteligencia artificial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DEPENDENCIAS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos las dependencias y librerías necesarias para el desarrollo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RUTAS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo la ruta para las imágenes de entrenamiento y prueba y una función para cargar al modelo con todas las imágenes de la dirección dada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv_path = './data/train.csv'\n",
    "test_csv_path = './data/test.csv'\n",
    "sol_csv_path = './data/sample_submision.csv'\n",
    "\n",
    "TRAIN_PATH = './train/train/'\n",
    "TEST_PATH = './test/test/'\n",
    "path_sol = './test_2/solution/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PRUEBAS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leo una única imagen para realizar las pruebas de limpieza, efectos y filtrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('./train/train/clips-30002.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256, 3)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imshow('img', img)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mi primera forma de afrontar el reto es dividiendo la imagen original en los **tres** canales de color que componen cualquier imagen en escala *RGB*. La imagen consta de unos cuatro colores en total: gris, blanco, rojo y azul. \n",
    "\n",
    "Para eliminar las líneas que ensucian mi imagen y meten ruido a mi detección de objetos, me quedo con la imagen en uno de esos canales únicamente para así eliminarme las líneas del mismo color predominante, el azul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LIMPIEZA Y LÍNEAS HORIZONTALES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformo la imagen a rgb, que por defecto es interpretada por opencv como BGR\n",
    "rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#espacio en blanco para la máscara\n",
    "blank = np.zeros(img.shape[:2], dtype='uint8')\n",
    "\n",
    "#divido por bandas de color\n",
    "b,g,r = cv.split(img)\n",
    "\n",
    "#uno con el espacio vacío cada color\n",
    "blue = cv.merge([b,blank,blank])\n",
    "green = cv.merge([blank,g,blank])\n",
    "red = cv.merge([blank,blank,r])\n",
    "\n",
    "#la azul es la que mejor funciona\n",
    "\n",
    "cv.imshow('blue', b)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aplico un desenfoque para que el modelo encuentre a grosso modo los objetos\n",
    "blur = cv.GaussianBlur(b, (3,3), cv.BORDER_DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#binarizamos la imagen a partir del desenfoque de la capa de azul\n",
    "ret, thresh = cv.threshold(blur, 225, 255, 1, cv.THRESH_BINARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#la invertimos\n",
    "thresh = 255 - thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#destaco los contornos y hago pruebas de valores\n",
    "canny = cv.Canny(thresh, 0, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dilatamos los contornos obtenidos\n",
    "dilated = cv.dilate(canny, (15,15), iterations=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#erosionamos la dilatación previa\n",
    "eroded = cv.erode(dilated, (7,7), iterations=1)\n",
    "cv.imshow('dilated', dilated)\n",
    "cv.imwrite('./img/imagen_limpia.jpg', eroded)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Imagen limpia hasta ahora](\\img\\imagen_limpia.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí podemos ver que el trabajo hasta ahora de limpieza ha resultado efectivo y que hemos conseguido aislar casi del todo los clips del resto del fondo. A falta de la línea vertical de la izquierda que marca el margen del cuaderno. Para esa línea, aplicaremos una máscara que detecte líneas verticales en la imagen y sustituya los píxeles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 contour(s) found!\n"
     ]
    }
   ],
   "source": [
    "contours, hierarchy = cv.findContours(eroded, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_NONE)\n",
    "print(f'{len(contours)} contour(s) found!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si hacemos un conteo de contornos empleando la propia herramienta de *OPEN CV*, podemos ver que los contornos encontrados coinciden con los contornos de la imagen (dos clips y la línea)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LÍNEAS VERTICALES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#buscamos elementos verticales en la última modificación de nuestra imagen \"eroded\"\n",
    "vertical_kernel = cv.getStructuringElement(cv.MORPH_RECT, (1, 100))\n",
    "detected_lines_vertical = cv.morphologyEx(eroded, cv.MORPH_OPEN, vertical_kernel, iterations=1)\n",
    "cnts_vertical, _ = cv.findContours(detected_lines_vertical, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "#creamos la máscara y sustituimos\n",
    "mask_vertical = np.zeros_like(eroded)\n",
    "for cnt_vertical in cnts_vertical:\n",
    "    x, y, w, h = cv.boundingRect(cnt_vertical)\n",
    "    cv.rectangle(mask_vertical, (x, y), (x + w, y + h), 255, -1)\n",
    "\n",
    "#invertimos la máscara\n",
    "mask_inverted_vertical = cv.bitwise_not(mask_vertical)\n",
    "\n",
    "#la aplicamos a nuestra imagen para que sustituya esos píxeles\n",
    "clean_img = cv.bitwise_and(eroded, eroded, mask=mask_inverted_vertical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vamos a ver cómo se ve ahora nuestra imagen sin línea vertical\n",
    "cv.imshow('imagen sin líneas verticales', clean_img)\n",
    "cv.imwrite('./img/imagen_limpia_2.jpg', clean_img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Imagen limpia hasta ahora](\\img\\imagen_limpia_2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya tenemos nuestra imagen con objetos a detectar aislados del fondo. Ahora vamos a poner en marcha nuestro algoritmo que detectará en toda la lista de imágenes los contornos y los añadirá a una tabla para entrenar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ENCAPSULAR**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encapsulamos en una única función todo el proceso anterior para pasar imagen a imagen por esta transformación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_img(img): \n",
    "    rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "    blank = np.zeros(img.shape[:2], dtype='uint8')\n",
    "    b,g,r = cv.split(img)\n",
    "    blur = cv.GaussianBlur(b, (3,3), cv.BORDER_DEFAULT)\n",
    "    ret, thresh = cv.threshold(blur, 225, 255, 1, cv.THRESH_BINARY)\n",
    "    thresh = 255 - thresh\n",
    "    canny = cv.Canny(thresh, 0, 25)\n",
    "    dilated = cv.dilate(canny, (15,15), iterations=2)\n",
    "    eroded = cv.erode(dilated, (7,7), iterations=1)\n",
    "    #verticales\n",
    "    vertical_kernel = cv.getStructuringElement(cv.MORPH_RECT, (1, 100))\n",
    "    detected_lines_vertical = cv.morphologyEx(eroded, cv.MORPH_OPEN, vertical_kernel, iterations=1)\n",
    "    cnts_vertical, _ = cv.findContours(detected_lines_vertical, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "    num_clips = len(cnts_vertical)\n",
    "    mask_vertical = np.zeros_like(eroded)\n",
    "    for cnt_vertical in cnts_vertical:\n",
    "        x, y, w, h = cv.boundingRect(cnt_vertical)\n",
    "        cv.rectangle(mask_vertical, (x, y), (x + w, y + h), 255, -1)\n",
    "    mask_inverted_vertical = cv.bitwise_not(mask_vertical)\n",
    "    clean_img = cv.bitwise_and(eroded, eroded, mask=mask_inverted_vertical)\n",
    "    \n",
    "    return clean_img, num_clips\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encapsulamos ahora en una función el proceso de **lectura de imágenes** además de **procesamiento**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    X = []\n",
    "    num_clips_list = []\n",
    "    for img in os.listdir(path):\n",
    "        image = cv.imread(os.path.join(path, img))\n",
    "\n",
    "        if image is not None:\n",
    "            img_masked, num_clips = cleaning_img(image)\n",
    "\n",
    "            if img_masked is not None:\n",
    "                smallimage = cv.resize(img_masked, (96, 96))\n",
    "                smallimage = smallimage / 255.0  # Normalizar\n",
    "                X.append(smallimage)  # X: images\n",
    "                num_clips_list.append(int(num_clips))  # número de clips\n",
    "\n",
    "    return np.array(X), np.array(num_clips_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CARGAMOS IMÁGENES DE TRAIN Y TEST PARA LA X**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,names_train = read_data(TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 96, 96)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test,names_test = read_data(TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 96, 96)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sol,names_sol = read_data(path_sol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 96, 96)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sol.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CARGAMOS DF DE TRAIN Y TEST PARA LA Y**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(train_csv_path)\n",
    "df_test = pd.read_csv(test_csv_path)\n",
    "df_sol = pd.read_csv(sol_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 2)\n",
      "(5000, 1)\n",
      "(5000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "print(df_test.shape)\n",
    "print(df_sol.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train['clip_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = df_sol['clip_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pasamos a float\n",
    "y_train = y_train.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos shape de cada una"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 96, 96)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000,)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 96, 96)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 96, 96)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sol.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.concatenate([X_test, X_sol])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_test = np.concatenate([names_test, names_sol])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 96, 96)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**APLICACIÓN DE MODELO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defino un modelo de cnn sencillo para empezar\n",
    "model = keras.Sequential([\n",
    "    layers.Flatten(input_shape=(96, 96)), \n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(1, activation='linear')    #capa de salida con activación linear para la problemática de regresión\n",
    "])\n",
    "\n",
    "#compilamos\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error', \n",
    "              metrics=['mae'])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 12s 11ms/step - loss: 3.1401 - mae: 1.4392\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 1.5199 - mae: 0.9933\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 0.9051 - mae: 0.7734\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.4873 - mae: 0.5719\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 0.2820 - mae: 0.4390\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 0.1697 - mae: 0.3413\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 0.1125 - mae: 0.2741\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 0.0843 - mae: 0.2313\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.0713 - mae: 0.2043\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 5s 12ms/step - loss: 0.0679 - mae: 0.1922\n",
      "157/157 [==============================] - 7s 2ms/step - loss: 0.6544 - mae: 0.6102\n",
      "Test Mean Absolute Error: 0.6102099418640137\n"
     ]
    }
   ],
   "source": [
    "#entrenamiento\n",
    "model.fit(X_train, names_train, epochs=10)\n",
    "\n",
    "#evaluación\n",
    "test_loss, test_mae = model.evaluate(X_test, names_test)\n",
    "print(f'Test Mean Absolute Error: {test_mae}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
