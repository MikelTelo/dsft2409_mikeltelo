{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Librerías estándar\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ✅ OpenCV para preprocesamiento de imágenes\n",
    "import cv2 as cv\n",
    "\n",
    "# ✅ Librerías de TensorFlow y Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.regularizers import l2  # ¡Importante para regularización!\n",
    "\n",
    "# ✅ Librería para división de datos\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Rutas de Datos\n",
    "ruta_train_csv = r'C:\\Users\\mikel\\OneDrive\\Documentos\\TB-DS-BIO-23.09.24\\REPOSITORIOS\\Mikel\\clip_count\\train.csv'\n",
    "ruta_test_csv = r'C:\\Users\\mikel\\OneDrive\\Documentos\\TB-DS-BIO-23.09.24\\REPOSITORIOS\\Mikel\\clip_count\\test.csv'\n",
    "ruta_train_img = r'C:\\Users\\mikel\\OneDrive\\Documentos\\TB-DS-BIO-23.09.24\\REPOSITORIOS\\Mikel\\clip_count\\train'\n",
    "ruta_test_img = r'C:\\Users\\mikel\\OneDrive\\Documentos\\TB-DS-BIO-23.09.24\\REPOSITORIOS\\Mikel\\clip_count\\test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id  clip_count\n",
      "0  30001          11\n",
      "1  30002           2\n",
      "2  30003          26\n",
      "3  30004          41\n",
      "4  30005          49\n",
      "      id\n",
      "0  45001\n",
      "1  45002\n",
      "2  45003\n",
      "3  45004\n",
      "4  45005\n"
     ]
    }
   ],
   "source": [
    "# ✅ Cargar datos de entrenamiento\n",
    "df_train = pd.read_csv(ruta_train_csv)\n",
    "df_test = pd.read_csv(ruta_test_csv)\n",
    "\n",
    "# ✅ Mostrar las primeras filas\n",
    "print(df_train.head())\n",
    "print(df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>clip_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>37500.500000</td>\n",
       "      <td>37.290133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4330.271354</td>\n",
       "      <td>21.922691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>30001.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>33750.750000</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37500.500000</td>\n",
       "      <td>37.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>41250.250000</td>\n",
       "      <td>56.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>45000.000000</td>\n",
       "      <td>75.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id    clip_count\n",
       "count  15000.000000  15000.000000\n",
       "mean   37500.500000     37.290133\n",
       "std     4330.271354     21.922691\n",
       "min    30001.000000      0.000000\n",
       "25%    33750.750000     18.000000\n",
       "50%    37500.500000     37.000000\n",
       "75%    41250.250000     56.000000\n",
       "max    45000.000000     75.000000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Corregir las rutas de las imágenes en los DataFrames\n",
    "df_train['image_path'] = df_train['id'].apply(lambda x: os.path.join(ruta_train_img, f\"clips-{x}.png\"))\n",
    "df_test['image_path'] = df_test['id'].apply(lambda x: os.path.join(ruta_test_img, f\"clips-{x}.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de entrenamiento: 12000\n",
      "Tamaño de validación: 3000\n"
     ]
    }
   ],
   "source": [
    "# ✅ Dividir en entrenamiento y validación (80% entrenamiento, 20% validación)\n",
    "train_df, val_df = train_test_split(df_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# ✅ Mostrar tamaños\n",
    "print(f\"Tamaño de entrenamiento: {len(train_df)}\")\n",
    "print(f\"Tamaño de validación: {len(val_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (15000, 128, 128, 1), y_train shape: (15000,)\n",
      "X_val shape: (3000, 128, 128, 1), y_val shape: (3000,)\n"
     ]
    }
   ],
   "source": [
    "# ✅ Función mejorada para cargar y preprocesar imágenes\n",
    "def load_and_preprocess_image(image_path):\n",
    "    \"\"\"\n",
    "    Carga una imagen en escala de grises, la redimensiona y la normaliza.\n",
    "    Si la imagen no existe o no puede cargarse, devuelve una imagen vacía.\n",
    "    \"\"\"\n",
    "    img = cv.imread(image_path, cv.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        print(f\"⚠️ No se pudo cargar la imagen: {image_path}\")\n",
    "        return np.zeros((128, 128))  # Imagen vacía para mantener la consistencia\n",
    "    \n",
    "    img = cv.resize(img, (128, 128))  # Redimensionar a 128x128\n",
    "    img = img / 255.0  # Normalizar a valores entre 0 y 1\n",
    "    return img\n",
    "\n",
    "# ✅ Cargar imágenes y etiquetas con manejo de errores\n",
    "X_train = np.array([load_and_preprocess_image(path) for path in df_train['image_path']])\n",
    "y_train = df_train['clip_count'].values\n",
    "\n",
    "X_val = np.array([load_and_preprocess_image(path) for path in val_df['image_path']])\n",
    "y_val = val_df['clip_count'].values\n",
    "\n",
    "# ✅ Agregar un canal extra para la compatibilidad con CNN\n",
    "X_train = X_train[..., np.newaxis]\n",
    "X_val = X_val[..., np.newaxis]\n",
    "\n",
    "# ✅ Mostrar formas de los datos\n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}, y_val shape: {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 528ms/step - loss: 247.2716 - root_mean_squared_error: 14.8164 - val_loss: 29871.8027 - val_root_mean_squared_error: 172.8342 - learning_rate: 5.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 538ms/step - loss: 99.0751 - root_mean_squared_error: 9.9444 - val_loss: 19475.9453 - val_root_mean_squared_error: 139.5557 - learning_rate: 5.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m 11/235\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:58\u001b[0m 528ms/step - loss: 84.0313 - root_mean_squared_error: 9.1525"
     ]
    }
   ],
   "source": [
    "# ✅ Modelo simplificado y corregido\n",
    "model = Sequential([\n",
    "    Input(shape=(128, 128, 1)),  # Capa de entrada corregida\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(0.001)),  # Regularización L2\n",
    "    Dropout(0.3),  # Ligera reducción en Dropout\n",
    "    Dense(1)  # Capa de salida para regresión\n",
    "])\n",
    "\n",
    "# ✅ Compilar el modelo con un learning rate ajustado\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0005),  # Ajuste fino del learning rate\n",
    "    loss='mean_squared_error',\n",
    "    metrics=[RootMeanSquaredError()]\n",
    ")\n",
    "\n",
    "# ✅ Callbacks\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=0.00001,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ✅ Entrenar el modelo SIN Data Augmentation (por ahora)\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=50,\n",
    "    batch_size=64,  # Mantener tamaño moderado\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ✅ Graficar la pérdida y el RMSE\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Pérdida\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Entrenamiento')\n",
    "plt.plot(history.history['val_loss'], label='Validación')\n",
    "plt.title('Pérdida durante el entrenamiento')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.legend()\n",
    "\n",
    "# RMSE\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['root_mean_squared_error'], label='Entrenamiento')\n",
    "plt.plot(history.history['val_root_mean_squared_error'], label='Validación')\n",
    "plt.title('RMSE durante el entrenamiento')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Evaluar en el conjunto de validación\n",
    "val_loss, val_rmse = model.evaluate(X_val, y_val)\n",
    "print(f\"Validación RMSE: {val_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Realizar predicciones en el conjunto de prueba\n",
    "X_test = np.array([load_and_preprocess_image(path) for path in df_test['image_path']])\n",
    "X_test = X_test[..., np.newaxis]\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "df_test['clip_count'] = predictions\n",
    "\n",
    "# ✅ Guardar predicciones\n",
    "df_test[['id', 'clip_count']].to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
